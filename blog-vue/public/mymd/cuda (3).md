# 学习日记-cuda(3)
## cuda内存访问模式
### **对齐与合并访问**
![process](/mymd/学习日记-cuda（3）/process.png)
* 核函数运行时每次读内存，哪怕是读一个字节的变量，也要读128字节，或者32字节，而具体是到底是32还是128还是要看访问方式
* 对于CPU来说，一级缓存或者二级缓存是不能被编程的，但是CUDA是支持通过编译指令停用一级缓存的。如果启用一级缓存，那么每次从DRAM上加载数据的粒度是128字节，如果不适用一级缓存，只是用二级缓存，那么粒度是32字节
* 要最关注的是以下两个特性:对齐内存访问;合并内存访问
* 我们把一次内存请求——也就是从内核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）
* 当一个内存事务的首个访问地址是缓存粒度（32或128字节）的偶数倍的时候：比如二级缓存32字节的偶数倍64，128字节的偶数倍256的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，非对齐的内存访问会造成带宽浪费
* 当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。对齐合并访问的状态是理想化的，也是最高速的访问方式，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了

![ex1](/mymd/学习日记-cuda（3）/ex1.png)
* 这里总结一下内存事务的优化关键：用最少的事务次数满足最多的内存请求。事务数量和吞吐量的需求随设备的计算能力变化
### **全局内存读取**
* 控制全局加载操作是否通过一级缓存可以通过编译选项来控制,编译器禁用一级缓存的选项是：`-Xptxas -dlcm=cg`，编译器启用一级缓存的选项是：`-Xptxas -dlcm=ca`
* 在有些设备上一级缓存不用来缓存全局内存访问，而是只用来存储寄存器溢出的本地数据，比如Kepler 的K10,K20。
* 内存访问有以下特点：
    * 是否使用缓存：一级缓存是否介入加载过程
    * 对齐与非对齐的：如果访问的第一个地址是32的倍数
    * 合并与非合并，访问连续数据块则是合并的
* 没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。
### **只读缓存**
* 只读缓存最初是留给纹理内存加载用的，在3.5以上的设备，只读缓存也支持使用全局内存加载代替一级缓存。也就是说3.5以后的设备，可以通过只读缓存从全局内存中读数据了。
只读缓存粒度32字节，对于分散读取，细粒度优于一级缓存
有两种方法指导内存从只读缓存读取：使用函数 _ldg；在间接引用的指针上使用修饰符
```__global__ void copyKernel(float * in,float* out)
{
    int idx=blockDim*blockIdx.x+threadIdx.x;
    out[idx]=__ldg(&in[idx]);

}
```
### **全局内存写入**
* 内存的写入和读取（或者叫做加载）是完全不同的，并且写入相对简单很多。一级缓存不能用在 Fermi 和 Kepler GPU上进行存储操作，发送到设备前，只经过二级缓存，存储操作在32个字节的粒度上执行，内存事务也被分为一段两端或者四段，如果两个地址在一个128字节的段内但不在64字节范围内，则会产生一个四段的事务，其他情况以此类推。
### **结构体数组与数组结构体**
* 即AOS和SOA
* 并行编程范式，尤其是SIMD（单指令多数据）对SoA更友好。CUDA中普遍倾向于SoA因为这种内存访问可以有效地合并。