# 学习日记-cuda(2)
## cuda内存模型
### **内存模型分类**
* 寄存器
* 共享内存
* 本地内存
* 常量内存
* 纹理内存
* 全局内存
* 上述各种都有自己的作用域，生命周期和缓存行为。CUDA中每个线程都有自己的私有的本地内存；线程块有自己的共享内存，对线程块内所有线程可见；所有线程都能访问读取常量内存和纹理内存，但是不能写，因为他们是只读的；全局内存，常量内存和纹理内存空间有不同的用途。对于一个应用来说，全局内存，常量内存和纹理内存有相同的生命周期。

![memory](/mymd/学习日记-cuda（2）/memory.png)
1. 寄存器
    * 为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，ex:
    * ``__global__ void
    __lauch_bounds__(maxThreadaPerBlock,minBlocksPerMultiprocessor)``
    * maxThreadaPerBlock：线程块内包含的最大线程数，线程块由核函数来启动
    * minBlocksPerMultiprocessor：可选参数，每个SM中预期的最小的常驻内存块参数。
    * 也可以在编译选项中加入`-maxrregcount=32`来控制一个编译单元里所有核函数使用的最大寄存器数量
2. 本地内存
    * 本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于2.0以上的设备，本地内存存储在每个SM的一级缓存，或者设备的二级缓存上。
3. 共享内存
    * 用`__share__`修饰，每个SM都有一定数量的由线程块分配的共享内存，共享内存是片上内存，跟主存相比，速度要快很多，也即是延迟低，带宽高。其类似于一级缓存，但是可以被编程。
    * 使用共享内存的时候一定要注意，不要因为过度使用共享内存，而导致SM上活跃的线程束减少，也就是说，一个线程块使用的共享内存过多，导致更过的线程块没办法被SM启动，这样影响活跃的线程束数量。
    * 共享内存在核函数内声明，生命周期和线程块一致，线程块运行开始，此块的共享内存被分配，当此块结束，则共享内存被释放。
    * 因为共享内存是块内线程可见的，所以就有竞争问题的存在，也可以通过共享内存进行通信，当然，为了避免内存竞争，可以使用同步语句`void__syncthreads();`，注意，频繁使用会影响内核执行效率。
    * SM中的一级缓存，和共享内存共享一个片上内存，他们通过静态划分，划分彼此的容量，运行时可以通过下面语句进行设置：`cudaError_t cudaFuncSetCacheConfig(const void * func,enum cudaFuncCache);`,这个函数可以设置内核的共享内存和一级缓存之间的比例。cudaFuncCache参数可选如下配置：
    * `cudaFuncCachePreferNone//无参考值，默认设置
    cudaFuncCachePreferShared//48k共享内存，16k一级缓存
    cudaFuncCachePreferL1// 48k一级缓存，16k共享内存
    cudaFuncCachePreferEqual// 32k一级缓存，32k共享内存`
4. 常量内存
    * 常量内存驻留在设备内存中，每个SM都有专用的常量内存缓存，常量内存使用：`__constant__`
    * 常量内存在核函数外，全局范围内声明，对于所有设备，只可以声明64k的常量内存，常量内存静态声明，并对同一编译单元中的所有核函数可见。常量内存显然是不能被修改的，这里不能被修改指的是被核函数修改，主机端代码是可以初始化常量内存的`cudaError_t cudaMemcpyToSymbol(const void* symbol,const void *src,size_t count);`
5. 纹理内存
    * 纹理内存驻留在设备内存中，在每个SM的只读缓存中缓存，纹理内存是通过指定的缓存访问的全局内存，只读缓存包括硬件滤波的支持，它可以将浮点插入作为读取过程中的一部分来执行，纹理内存是对二维空间局部性的优化。
    * 总的来说纹理内存设计目的应该是为了GPU本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。
6. 全局内存
    * GPU上最大的内存空间，延迟最高，使用最常见的内存，global指的是作用域和生命周期，一般在主机端代码里定义，也可以在设备端定义，不过需要加修饰符，只要不销毁，是和应用程序同生命周期的。全局内存对应于设备内存，一个是逻辑表示，一个是硬件表示、
    * 全局内存可以动态声明，或者静态声明，可以用下面的修饰符在设备代码中静态的声明一个变量：`__device__`
    * 全局内存访问是对齐，也就是一次要读取指定大小（32，64，128）整数倍字节的内存，所以当线程束执行内存加载/存储时，需要满足的传输数量通常取决与以下两个因素：跨线程的内存地址分布;内存事务的对齐方式。
### **GPU缓存**
1. 与CPU缓存类似，GPU缓存不可编程，其行为出厂是时已经设定好了。GPU上有4种缓存：一级缓存;二级缓存;只读常量缓存;只读纹理缓存
2. 每个SM都有一个一级缓存，所有SM公用一个二级缓存。一级二级缓存的作用都是被用来存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。Fermi，Kepler以及以后的设备，CUDA允许我们配置读操作的数据是使用一级缓存和二级缓存，还是只使用二级缓存。
3. 每个SM有一个只读常量缓存，只读纹理缓存，它们用于设备内存中提高来自于各自内存空间内的读取性能

| 修饰符 | 变量名称 | 存储器 | 作用域 | 生命周期 |
| :-----| ----: | :----: | :----: | :----: |
| | float var|	寄存器|	线程|	线程|
| | float var[100]|	本地|	线程|	线程|
|__share__|	float var*|	共享|	块|	块|
|__device__|	float var*|	全局|	全局|	应用程序|
|__constant|	float var*|	常量|	全局	|应用程序|